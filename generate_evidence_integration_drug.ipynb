{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cLwDd7S3aJ-eGZtLh8OVCYAP4QXwABBv",
      "authorship_tag": "ABX9TyP+/lRIc+Yqx3Rnv910VCWY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahopman/IEMB-Net/blob/main/generate_evidence_integration_drug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Mih0tee-j92g"
      },
      "outputs": [],
      "source": [
        "__author__ = 'Qiao Jin'\n",
        "__editor__ = 'Mia Hopman'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_path = '/content/drive/MyDrive/MS_DataScience/DS595/IEBM-Net_Data'\n",
        "evidence_integration_path = f'{local_path}/evidence_integration'"
      ],
      "metadata": {
        "id": "CtTIvpPOlE9h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def generate(picoids, split_path):\n",
        "\toutput = []\n",
        "\tfor picoid in picoids:\n",
        "\t\tif prompt_info[picoid]['label'] != 'invalid prompt':\n",
        "\t\t\toutput.append({})\n",
        "\t\t\toutput[-1]['picoid'] = picoid\n",
        "\t\t\toutput[-1]['pmcid'] = prompt_info[picoid]['PMCID']\n",
        "\t\t\toutput[-1]['i_text'] = prompt_info[picoid]['I']\n",
        "\t\t\toutput[-1]['c_text'] = prompt_info[picoid]['C']\n",
        "\t\t\toutput[-1]['o_text'] = prompt_info[picoid]['O']\n",
        "\t\t\toutput[-1]['label'] = result2label[prompt_info[picoid]['label']]\n",
        "\n",
        "\t\t\tpassage = ''\n",
        "\t\t\tif str(prompt_info[picoid]['PMCID']) in pmcid2content:\n",
        "\t\t\t\tcontent = pmcid2content[str(prompt_info[picoid]['PMCID'])]\n",
        "\t\t\t\tfor secname, text in content:\n",
        "\t\t\t\t\tif secname[:len('ABSTRACT')] != 'ABSTRACT': continue\n",
        "\t\t\t\t\tif sec2label[secname2sec[secname]] == '1':\n",
        "\t\t\t\t\t\tpassage += text\n",
        "\n",
        "\t\t\toutput[-1]['passage'] = passage\n",
        "\n",
        "\twith open(split_path, 'w') as f:\n",
        "\t\tjson.dump(output, f, indent=4)"
      ],
      "metadata": {
        "id": "0r0DUozrk91V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "prompts_df = pd.read_csv(f'{evidence_integration_path}/evidence_inference/prompts_merged.csv')\n",
        "annotations_df = pd.read_csv(f'{evidence_integration_path}/evidence_inference/annotations_merged.csv')\n",
        "\n",
        "annotations_df = annotations_df.loc[\n",
        "    (annotations_df['Valid Label'] == True) &\n",
        "    (annotations_df['Valid Reasoning'] == True)\n",
        "]\n",
        "\n",
        "annotations_df = annotations_df[['PromptID','Label']].drop_duplicates()\n",
        "\n",
        "prompts_info_df = pd.merge(prompts_df, annotations_df, on='PromptID')\n",
        "\n",
        "prompt_info = {}\n",
        "for _, row in prompts_info_df.iterrows():\n",
        "    picoid = row['PromptID']\n",
        "    prompt_info[picoid] = {}\n",
        "    prompt_info[picoid]['PMCID'] = row['PMCID']\n",
        "    prompt_info[picoid]['I'] = row['Intervention']\n",
        "    prompt_info[picoid]['C'] = row['Comparator']\n",
        "    prompt_info[picoid]['O'] = row['Outcome']\n",
        "    prompt_info[picoid]['label'] = row['Label']\n",
        "\n",
        "with open(f'{evidence_integration_path}/evidence_inference/prompt_info.json', 'w') as f:\n",
        "    json.dump(prompt_info, f, indent=4)"
      ],
      "metadata": {
        "id": "VmDUvnV6mgR8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y8xmWhjjtwZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result2label = {'significantly decreased': 0,\\\n",
        "\t\t\t\t'no significant difference': 1,\\\n",
        "\t\t\t\t'significantly increased': 2}\n",
        "\n",
        "prompt_info = json.load(open(local_path + '/evidence_integration/materials/prompt_info.json'))\n",
        "split2ids = json.load(open(local_path + '/evidence_integration/materials/split2ids.json'))\n",
        "pmcid2picoid = json.load(open(local_path + '/evidence_integration/materials/pmcid2picoid.json'))\n",
        "pmcid2content = json.load(open(local_path + '/evidence_integration/materials/pmc_contents.json'))\n",
        "secname2sec = json.load(open(local_path + '/evidence_integration/materials/secname2sec.json'))\n",
        "sec2label = json.load(open(local_path + '/evidence_integration/materials/sec2label.json'))\n",
        "\n",
        "for split, ids in split2ids.items():\n",
        "    picoids = []\n",
        "\n",
        "    for pmcid in ids:\n",
        "\t    pmcid = str(pmcid)\n",
        "        if pmcid in pmcid2picoid:\n",
        "\t\t    picoids += pmcid2picoid[pmcid]\n",
        "\n",
        "    split_path = f\"{local_path}/evidence_integration/{split}.json\"\n",
        "    generate(picoids, split_path)"
      ],
      "metadata": {
        "id": "fdW1zFU_lD6L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}