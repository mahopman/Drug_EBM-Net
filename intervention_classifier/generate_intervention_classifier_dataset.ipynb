{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGPxs8cy5G8pJZfRMkTrA5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahopman/IEBM-Net/blob/main/intervention_classifier/generate_intervention_classifier_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_path = '/content/drive/MyDrive/MS_DataScience/DS595/IEBM-Net_Data'\n",
        "evidence_integration_path = f'{local_path}/evidence_integration'\n",
        "pretraining_dataset_path = f'{local_path}/pretraining_dataset'"
      ],
      "metadata": {
        "id": "IRGlm5uuFiMu"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "41xyC77TFbRd"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "pmcid2intervention = json.load(open(f'{evidence_integration_path}/pmcid2intervention.json'))\n",
        "pmcid2content = json.load(open(f'{evidence_integration_path}/evidence_inference/pmc_contents.json'))\n",
        "sec2label = json.load(open(f'{evidence_integration_path}/evidence_inference/sec2label.json'))\n",
        "secname2sec = json.load(open(f'{evidence_integration_path}/evidence_inference/secname2sec.json'))\n",
        "\n",
        "dataset = {}\n",
        "ctx_id = 0\n",
        "\n",
        "for pmcid in pmcid2intervention:\n",
        "    passage = ''\n",
        "    if pmcid in pmcid2content:\n",
        "        content = pmcid2content[pmcid]\n",
        "        for secname, text in content:\n",
        "            if secname[:len('ABSTRACT')] != 'ABSTRACT': continue\n",
        "            if sec2label[secname2sec[secname]] == '1':\n",
        "                passage += text\n",
        "\n",
        "        dataset[ctx_id] = {}\n",
        "        dataset[ctx_id]['passage'] = passage\n",
        "        dataset[ctx_id]['intervention'] = pmcid2intervention[pmcid]\n",
        "        ctx_id += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "pmid2intervention = json.load(open(f'{pretraining_dataset_path}/pmid2intervention.json'))\n",
        "\n",
        "files = glob.glob(f'{pretraining_dataset_path}/evidence/contexts_*.json')\n",
        "\n",
        "for file in files:\n",
        "    data = json.load(open(file))\n",
        "\n",
        "    for entry in data:\n",
        "        pmid = entry['pmid']\n",
        "        if pmid in pmid2intervention:\n",
        "            dataset[ctx_id] = {}\n",
        "            dataset[ctx_id]['passage'] = entry['ctx']\n",
        "            dataset[ctx_id]['intervention'] = pmid2intervention[pmid]\n",
        "            ctx_id += 1"
      ],
      "metadata": {
        "id": "i7Dn00toISEw"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "n = ctx_id\n",
        "train_size = int(n * 0.7)\n",
        "val_size = int(n * 0.15)\n",
        "test_size = n - train_size - val_size\n",
        "\n",
        "# Get indices for each section\n",
        "train_indices = np.random.choice(n, train_size, replace=False)\n",
        "val_indices = np.random.choice(list(set(range(n)) - set(train_indices)), val_size, replace=False)\n",
        "test_indices = list(set(range(n)) - set(train_indices) - set(val_indices))\n",
        "\n",
        "# Split the dataset\n",
        "train = {k: v for k, v in dataset.items() if k in train_indices}\n",
        "val = {k: v for k, v in dataset.items() if k in val_indices}\n",
        "test = {k: v for k, v in dataset.items() if k in test_indices}"
      ],
      "metadata": {
        "id": "NybgcBfaNMkT"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'{local_path}/intervention_classifier/train.json', 'w') as f:\n",
        "    json.dump(train, f)\n",
        "\n",
        "with open(f'{local_path}/intervention_classifier/test.json', 'w') as f:\n",
        "    json.dump(test, f)\n",
        "\n",
        "with open(f'{local_path}/intervention_classifier/val.json', 'w') as f:\n",
        "    json.dump(val, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTuWeD1wLTAW",
        "outputId": "e10795ad-1281-4ba0-eda7-b156d24ac8b2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'passage': \" We examined the effect of a telemedical coaching (TMC) programme accompanied with or without telemonitoring on weight loss in an occupational healthcare setting with a three-armed randomised controlled trial (NCT01837134 'Pre-results'). Overweight employees (n=104, body mass index [BMI] â‰¥25\\u2009kg/m\",\n",
              " 'intervention': ['DEVICE', 'BEHAVIORAL']}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}