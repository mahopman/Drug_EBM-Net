{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1nYiOUEumGe1iRpaLOUX5blG27slJhZq_",
      "authorship_tag": "ABX9TyOx/C5th2zxdx/n5Ak9QM+K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahopman/IEBM-Net/blob/main/intervention_classifier/intervention_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_path = '/content/drive/MyDrive/MS_DataScience/DS595/CTP'\n",
        "classifier_path = f'{local_path}/intervention_classifier'"
      ],
      "metadata": {
        "id": "x6Kvi-bpe242"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from transformers.file_utils import is_torch_available, is_tf_available\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    if is_torch_available():\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        # ^^ safe to call this function even if cuda is not available\n",
        "    if is_tf_available():\n",
        "        import tensorflow as tf\n",
        "\n",
        "        tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "oGYnwPMNWwBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class InterventionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "PO46lUnCW0h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    true = pred.label_ids\n",
        "    pred = pred.predictions.argmax(-1)\n",
        "\n",
        "    precision = precision_score(true, pred)\n",
        "    recall = recall_score(true, pred)\n",
        "    accuracy = accuracy_score(true, pred)\n",
        "    f1 = f1_score(true, pred)\n",
        "\n",
        "    return {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1\n",
        "    }"
      ],
      "metadata": {
        "id": "E1GtzLykW2Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "train = json.load(open(f'{classifier_path}/train.json'))\n",
        "test = json.load(open(f'{classifier_path}/test.json'))\n",
        "val = json.load(open(f'{classifier_path}/val.json'))\n",
        "\n",
        "X_train = [x['text'] for x in train]\n",
        "X_test = [x['text'] for x in test]\n",
        "X_val = [x['text'] for x in val]\n",
        "\n",
        "y_train = [1 if 'DRUG' in x['label'] else 0 for x in train]\n",
        "y_test = [1 if 'DRUG' in x['label'] else 0 for x in test]\n",
        "y_val = [1 if 'DRUG' in x['label'] else 0 for x in val]"
      ],
      "metadata": {
        "id": "uWMlMjZbPyan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
        "\n",
        "set_seed(1)\n",
        "\n",
        "model_name = 'bert-base-uncased'\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)\n",
        "\n",
        "train_encodings = tokenizer(X_train.to_list(), truncation=True, padding=True)\n",
        "valid_encodings = tokenizer(X_test.to_list(), truncation=True, padding=True)\n",
        "\n",
        "train_dataset = InterventionDataset(train_encodings, X_train.to_list())\n",
        "valid_dataset = InterventionDataset(valid_encodings, X_test.to_list())\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2.to(\"cuda\")"
      ],
      "metadata": {
        "id": "CbzRgftQktMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir                  = f'{classifier_path}/results',\n",
        "    num_train_epochs            = 3,\n",
        "    per_device_train_batch_size = 8,\n",
        "    per_device_eval_batch_size  = 20,\n",
        "    warmup_steps                = 500,\n",
        "    weight_decay                = 0.01,\n",
        "    logging_dir                 = f'{classifier_path}/logs',\n",
        "    load_best_model_at_end      = True,\n",
        "    logging_steps               = 400,\n",
        "    save_steps                  = 400,\n",
        "    evaluation_strategy         = \"steps\",\n",
        ")"
      ],
      "metadata": {
        "id": "WRe_k459UWGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model           = model,\n",
        "    args            = training_args,\n",
        "    train_dataset   = train_dataset,\n",
        "    eval_dataset    = valid_dataset,\n",
        "    compute_metrics = compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "4-qwTwGoUYvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "tj5diSfhUawd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.evaluate()\n",
        "\n",
        "precision = results['eval_precision']\n",
        "recall = results['eval_recall']\n",
        "accuracy = results['eval_accuracy']\n",
        "precision = results['eval_precision']"
      ],
      "metadata": {
        "id": "T59aRmD8Udcm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}